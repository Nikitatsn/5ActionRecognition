{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0hZVRltPwHr"
      },
      "source": [
        "**Import**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_tvZpfEYExr"
      },
      "outputs": [],
      "source": [
        "!pip install av\n",
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rhbTqd28O-mn"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from torchvision.models.video import r2plus1d_18\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import time\n",
        "from torchvision.io import read_video\n",
        "import av\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zGPBO14UP3R6"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/data.csv')\n",
        "video_dir = '/content/drive/MyDrive/videos/..'\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyBgmRgqa_bU",
        "outputId": "3caeeb43-3fc1-4dca-fd7f-74bdfa506e6f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKK4jre_P3KH",
        "outputId": "f2886a28-4d8d-43ab-a3ee-671650274202"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0             name_video        label  target\n",
            "0           0  videos/video_0000.mp4  tap dancing      14\n",
            "1           1  videos/video_0001.mp4  tap dancing      14\n",
            "2           2  videos/video_0002.mp4  tap dancing      14\n",
            "3           3  videos/video_0003.mp4  tap dancing      14\n",
            "4           4  videos/video_0004.mp4  tap dancing      14\n"
          ]
        }
      ],
      "source": [
        "# Создание экземпляра LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(df['label'])\n",
        "df['target'] = encoded_labels\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w67bRHdFP27b"
      },
      "outputs": [],
      "source": [
        "\n",
        "class VideoDataset(Dataset):\n",
        "    def __init__(self, video_dir, df):\n",
        "        self.video_dir = video_dir\n",
        "        self.df = df\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        video_path = os.path.join(self.video_dir, self.df['name_video'].iloc[idx])\n",
        "        video, audio, info = read_video(video_path)\n",
        "        video = self.preprocess_video(video)\n",
        "\n",
        "        target = self.df['target'].iloc[idx]\n",
        "        target = torch.tensor(target, dtype=torch.long)  # Преобразование в Tensor\n",
        "\n",
        "        return video, target\n",
        "\n",
        "    def preprocess_video(self, video):\n",
        "\n",
        "        video = video.float()\n",
        "\n",
        "\n",
        "        resize_transform = transforms.Resize((112, 112))\n",
        "        video_resized = torch.stack([resize_transform(frame.permute(2, 0, 1)).permute(1, 2, 0) for frame in video])\n",
        "\n",
        "\n",
        "        num_frames = video_resized.shape[0]\n",
        "        desired_frames = 24\n",
        "        if num_frames < desired_frames:\n",
        "\n",
        "            last_frame = video_resized[-1]\n",
        "            frames_to_add = desired_frames - num_frames\n",
        "            video_resized = torch.cat([video_resized, last_frame.unsqueeze(0).expand(frames_to_add, -1, -1, -1)], dim=0)\n",
        "        elif num_frames > desired_frames:\n",
        "\n",
        "            video_resized = video_resized[:desired_frames]\n",
        "\n",
        "\n",
        "        video_normalized = video_resized.permute(3, 0, 1, 2) / 255.0\n",
        "\n",
        "\n",
        "        video_tensor = torch.cat([frame.unsqueeze(0) for frame in video_normalized], dim=0)\n",
        "\n",
        "        return video_tensor\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "video_dataset = VideoDataset(video_dir=\"/content/drive/MyDrive/videos/..\", df=df)\n",
        "\n",
        "\n",
        "video, target = video_dataset[0]\n",
        "print(\"Video tensor shape:\", video.shape)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H11f9l6qY_xe",
        "outputId": "5cf5fc92-48ea-4b70-bece-073cd517b1af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset size: 1874\n",
            "Validation dataset size: 468\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Определение параметров\n",
        "batch_size = 12\n",
        "validation_split = 0.2  # Доля данных, выделяемых под валидацию\n",
        "\n",
        "# Создание DataLoader для исходного датасета\n",
        "dataloader = DataLoader(video_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Вычисление размера валидационного набора данных\n",
        "val_size = int(len(video_dataset) * validation_split)\n",
        "train_size = len(video_dataset) - val_size\n",
        "\n",
        "# Разделение датасета на тренировочный и валидационный наборы данных\n",
        "train_dataset, val_dataset = random_split(video_dataset, [train_size, val_size])\n",
        "\n",
        "# Создание DataLoader для тренировочного и валидационного наборов данных\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Проверка размеров полученных датасетов и батчей\n",
        "print(\"Train dataset size:\", len(train_dataset))\n",
        "print(\"Validation dataset size:\", len(val_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGBBCS6UdzWy"
      },
      "outputs": [],
      "source": [
        "model = r2plus1d_18(pretrained=True)\n",
        "\n",
        "# Определение устройства (например, GPU, если доступно)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Перенос модели на выбранное устройство\n",
        "model = model.to(device)\n",
        "\n",
        "# Проверка устройства, на котором работает модель\n",
        "print(\"Device:\", device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "o5V1fcUioKbA"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_lr = 0.0001\n",
        "optimizer = optim.AdamW(model.parameters(), lr=optimizer_lr)\n",
        "num_epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "13Xxq-feY_fi",
        "outputId": "b29a86b8-2572-4fda-9d5c-679085b76518"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------epoch:1/10---------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [21:40<00:00,  8.29s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 1, lr_rate 0.0001\n",
            "loss_train: 0.2745 | loss_valid: 0.1823\n",
            "metric 43.58974358974359\n",
            "Elapsed time: 00:25:42\n",
            "-----------------------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-b9bc90d01bdd>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-----------------------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'scheduler' is not defined"
          ]
        }
      ],
      "source": [
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(\"---------------------epoch:{}/{}---------------------\".format(epoch+1, num_epochs))\n",
        "\n",
        "    # Train on the training data\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    train_correct = 0\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(tqdm(train_dataloader)):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        model = model.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs.to(device))\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    train_loss /= len(train_dataloader.dataset)\n",
        "    train_accuracy = 100.0 * train_correct / len(train_dataloader.dataset)\n",
        "\n",
        "    # Assign encoded labels to 'target' column in the DataFrame\n",
        "    df['target'] = encoded_labels\n",
        "\n",
        "    # Validate on the test data\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    test_correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            test_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    test_loss /= len(val_dataloader.dataset)\n",
        "    test_accuracy = 100.0 * test_correct / len(val_dataloader.dataset)\n",
        "\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "\n",
        "    # Print the results after each epoch\n",
        "    print(f\"\\nepoch: {epoch+1}, lr_rate {optimizer.param_groups[0]['lr']:.4f}\")\n",
        "    print(f\"loss_train: {train_loss:.4f} | loss_valid: {test_loss:.4f}\")\n",
        "    print(f\"metric {test_accuracy}\")\n",
        "    print(f\"Elapsed time: {time.strftime('%H:%M:%S', time.gmtime(elapsed_time))}\")\n",
        "    print(\"-----------------------------------------------\")\n",
        "\n",
        "    scheduler.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(\"---------------------epoch:{}/{}---------------------\".format(epoch+1, num_epochs))\n",
        "\n",
        "    # Train on the training data\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    train_correct = 0\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(tqdm(train_dataloader)):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        model = model.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs.to(device))\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    train_loss /= len(train_dataloader.dataset)\n",
        "    train_accuracy = 100.0 * train_correct / len(train_dataloader.dataset)\n",
        "\n",
        "    # Assign encoded labels to 'target' column in the DataFrame\n",
        "    df['target'] = encoded_labels\n",
        "\n",
        "    # Validate on the test data\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    test_correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            test_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    test_loss /= len(val_dataloader.dataset)\n",
        "    test_accuracy = 100.0 * test_correct / len(val_dataloader.dataset)\n",
        "\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "\n",
        "    # Print the results after each epoch\n",
        "    print(f\"\\nepoch: {epoch+1}, lr_rate {optimizer.param_groups[0]['lr']:.4f}\")\n",
        "    print(f\"loss_train: {train_loss:.4f} | loss_valid: {test_loss:.4f}\")\n",
        "    print(f\"metric {test_accuracy}\")\n",
        "    print(f\"Elapsed time: {time.strftime('%H:%M:%S', time.gmtime(elapsed_time))}\")\n",
        "    print(\"-----------------------------------------------\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 965
        },
        "id": "xkmzE0YPjQSd",
        "outputId": "1efc28ff-8dad-4e63-9b83-5a32991c5736"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------epoch:1/10---------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [10:47<00:00,  4.13s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 1, lr_rate 0.0001\n",
            "loss_train: 0.0583 | loss_valid: 0.1713\n",
            "metric 49.35897435897436\n",
            "Elapsed time: 00:12:20\n",
            "-----------------------------------------------\n",
            "---------------------epoch:2/10---------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [10:41<00:00,  4.09s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 2, lr_rate 0.0001\n",
            "loss_train: 0.0229 | loss_valid: 0.1903\n",
            "metric 50.427350427350426\n",
            "Elapsed time: 00:12:14\n",
            "-----------------------------------------------\n",
            "---------------------epoch:3/10---------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [10:40<00:00,  4.08s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 3, lr_rate 0.0001\n",
            "loss_train: 0.0114 | loss_valid: 0.1976\n",
            "metric 51.282051282051285\n",
            "Elapsed time: 00:12:13\n",
            "-----------------------------------------------\n",
            "---------------------epoch:4/10---------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [10:43<00:00,  4.10s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 4, lr_rate 0.0001\n",
            "loss_train: 0.0116 | loss_valid: 0.2109\n",
            "metric 50.427350427350426\n",
            "Elapsed time: 00:12:16\n",
            "-----------------------------------------------\n",
            "---------------------epoch:5/10---------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [10:51<00:00,  4.15s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "epoch: 5, lr_rate 0.0001\n",
            "loss_train: 0.0175 | loss_valid: 0.2169\n",
            "metric 47.863247863247864\n",
            "Elapsed time: 00:12:28\n",
            "-----------------------------------------------\n",
            "---------------------epoch:6/10---------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 1/157 [00:08<21:18,  8.19s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-8ea0332d2c4d>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mtrain_correct\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmELuh2fah4T"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}